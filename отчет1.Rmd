---
title: "Задание 3"
author: "А. С. Серкова"
date: '28 февраля 2018 г '
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


1.Построить модели на данных примера 3 с параметрами распределений, соответствующими своему варианту.  2.Определить, какой из методов срабатывает на этих данных лучше, и почему.

3.По матрице неточностей той модели, которая оказалась лучше по Acc, рассчитать характеристики качества и ошибки из лекции: TPR, SPC, PPV, NPV, FNR, FPR, FDR, MCC.

- n=100, доля обучающей выборки: 85%
x1.mean.1=13
x1.mean.2=24
x1.sd.1=9
x1.sd.2=5
x2.mean.1=13
x2.mean.2=14
x2.sd.1=8
x2.sd.2=13

```{r}
library('mlbench') 
library('class') 
library('car') 
library('class') 
library('e1071') 
library('MASS') 

# Данные примера 3 ............................................................. 
# ядро 
my.seed <- 12345 
n <- 60 # наблюдений всего 
train.percent <- 0.85 # доля обучающей выборки 
# x-ы — двумерные нормальные случайные величины 
set.seed(my.seed) 
class.0 <- mvrnorm(45, mu = c(13, 24), 
                   Sigma = matrix(c(9, 0, 0, 5), 2, 2, byrow = T)) 
set.seed(my.seed + 1) 
class.1 <- mvrnorm(65, mu = c(13, 14), 
                   Sigma = matrix(c(8, 0, 0, 13), 2, 2, byrow = T)) 
# записываем x-ы в единые векторы (объединяем классы 0 и 1) 
x1 <- c(class.0[, 1], class.1[, 1]) 
x2 <- c(class.0[, 2], class.1[, 2]) 
# фактические классы Y 
y <- c(rep(0, nrow(class.0)), rep(1, nrow(class.1))) 
# классы для наблюдений сетки 
rules <- function(x1, x2){ 
  ifelse(x2 < 1.6*x1 + 19, 0, 1) 
} 
# Конец данных примера 3 ....................................................... 
# Отбираем наблюдения в обучающую выборку —----------------------------------— 
set.seed(my.seed) 
inTrain <- sample(seq_along(x1), train.percent*n) 
x1.train <- x1[inTrain] 
x2.train <- x2[inTrain] 
x1.test <- x1[-inTrain] 
x2.test <- x2[-inTrain] 
# используем истинные правила, чтобы присвоить фактические классы 
y.train <- y[inTrain] 
y.test <- y[-inTrain] 
# фрейм с обучающей выборкой 
df.train.1 <- data.frame(x1 = x1.train, x2 = x2.train, y = y.train) 
# фрейм с тестовой выборкой 
df.test.1 <- data.frame(x1 = x1.test, x2 = x2.test) 

```

Изобразим фактическую обучающую выборку  на графике.

```{r}
# Рисуем обучающую выборку графике —-----------------------------------------— 
# для сетки (истинных областей классов): целочисленные значения x1, x2 

x1.grid <- rep(seq(floor(min(x1)), ceiling(max(x1)), by = 1), 
               ceiling(max(x2)) - floor(min(x2)) + 1) 
x2.grid <- rep(seq(floor(min(x2)), ceiling(max(x2)), by = 1), 
               each = ceiling(max(x1)) - floor(min(x1)) + 1) 
# классы для наблюдений сетки 
y.grid <- rules(x1.grid, x2.grid) 
# фрейм для сетки 
df.grid.1 <- data.frame(x1 = x1.grid, x2 = x2.grid, y = y.grid) 
# цвета для графиков 
cls <- c('blue', 'orange') 
cls.t <- c(rgb(0, 0, 1, alpha = 0.5), rgb(1,0.5,0, alpha = 0.5)) 
# график истинных классов 
plot(df.grid.1$x1, df.grid.1$x2, 
     pch = '·', col = cls[df.grid.1[, 'y'] + 1], 
     xlab = 'X1', ylab = 'Y1', 
     main = 'Обучающая выборка, факт') 
# точки фактических наблюдений 
points(df.train.1$x1, df.train.1$x2, 
       pch = 21, bg = cls.t[df.train.1[, 'y'] + 1], 
       col = cls.t[df.train.1[, 'y'] + 1]) 

```
 
 Обучим модель наивного байесовского классификатора и оценим её точность (верность) на обучающей выборке. Поскольку объясняющие переменные для классов сгенерированы как двумерные нормальные распределения и сами классы не перекрываются, следует ожидать, что эта модель окажется точной.
  
```{r}
# Байесовский классификатор —------------------------------------------------— 
# наивный байес: непрерывные объясняющие переменные 
# строим модель 
nb <- naiveBayes(y ~ ., data = df.train.1) 
# получаем модельные значения на обучающей выборке как классы 
y.nb.train <- ifelse(predict(nb, df.train.1[, -3], 
                             type = "raw")[, 2] > 0.5, 1, 0)
```

Построим обучающую выборку модели naiveBayes

```{r}
plot(df.grid.1$x1, df.grid.1$x2, 
     pch = '·', col = cls[df.grid.1[, 'y'] + 1], 
     xlab = 'X1', ylab = 'Y1', 
     main = 'Обучающая выборка, модель naiveBayes') 
# точки наблюдений, предсказанных по модели 
points(df.train.1$x1, df.train.1$x2, 
       pch = 21, bg = cls.t[y.nb.train + 1], 
       col = cls.t[y.nb.train + 1]) 
```

Матрица неточностей на обучающей выборке

```{r}
# матрица неточностей на обучающей выборке 
tbl <- table(y.train, y.nb.train) 
tbl
```

Точность или верность .

```{r}
# точность, или верность (Accuracy) 
Acc <- sum(diag(tbl)) / sum(tbl) 
Acc
```

Прогноз на тестовую выборку 

```{r }
# прогноз на тестовую выборку 
y.nb.test <- ifelse(predict(nb, df.test.1, type = "raw")[, 2] > 0.5, 1, 0) 
# матрица неточностей на тестовой выборке 
tbl <- table(y.test, y.nb.test) 
tbl 

# точность, или верность (Accuracy) 
Acc <- sum(diag(tbl)) / sum(tbl) 
Acc 

```

Метод kNN
К=3

```{r }
# строим модель и делаем прогноз 
y.knn.train <- knn(train = scale(df.train.1[, -3]), 
                   test = scale(df.train.1[, -3]), 
                   cl = df.train.1$y, k = 3) 

```
Построим график обучающей выборки модели KNN
```{r }
plot(df.grid.1$x1, df.grid.1$x2, 
     pch = '·', col = cls[df.grid.1[, 'y'] + 1], 
     xlab = 'X1', ylab = 'Y1', 
     main = 'Обучающая выборка, модель kNN') 
# точки наблюдений, предсказанных по модели 
points(df.train.1$x1, df.train.1$x2, 
       pch = 21, bg = cls.t[as.numeric(y.knn.train)], 
       col = cls.t[as.numeric(y.knn.train)])  

```



Прогноз на обучающей и тестовой выборке 

```{r}
# матрица неточностей на обучающей выборке 
tbl <- table(y.train, y.knn.train) 
tbl 

# точность (Accuracy) 
Acc <- sum(diag(tbl)) / sum(tbl) 
Acc 

# прогноз на тестовую выборку 
y.knn.test <- knn(train = scale(df.train.1[, -3]), 
                  test = scale(df.test.1[, -3]), 
                  cl = df.train.1$y, k = 3) 
# матрица неточностей на тестовой выборке 
tbl <- table(y.test, y.knn.test) 
tbl1<-tbl


# точность (Accuracy) 
Acc <- sum(diag(tbl)) / sum(tbl) 
Acc
```

Лучшим методом на этих данных оказался Наивный байесовский метод ,так как значение ACC=0.88 близок к 1. Поэтому все показатели будут расчитываться по тестовой матрице неточностей.

```{r} 
TPR=TPR=tbl1[2,2]/(tbl1[2,2]+tbl1[2,1]) 
TPR 
``` 

Чувстительность близка к 1, значит модель хорошо определяет наличие признака. 

```{r} 
SPC=tbl1[1,1]/(tbl1[2,1]+tbl1[1,1]) 
SPC 
``` 
Модель обладает высокой специфичностью, обеспечивает большую вероятность правильного распознавания для отрицательных примеров. 

```{r} 
PPV=tbl1[2,2]/(tbl1[2,2]+tbl1[2,1]) 
PPV 
NPV=tbl1[1,1]/(tbl1[1,2]+tbl1[1,1])
NPV 
``` 

Положительная прогностическая ценность и отрицательная прогностическая ценность достаточно велики, что свидетельстует о хорошем качестве модели. 

```{r} 
FNR=1-TPR 
FNR 
FPR=1-SPC 
FPR 
FDR=1-PPV 
FDR 
``` 

Ошибки не превышают 0,2, следовательно модель хорошего качества.

```{r} 
MCC=(tbl1[2,2]*tbl1[1,1]-tbl1[2,1]*tbl1[1,2])/(((tbl1[2,2]+tbl1[2,1])*(tbl1[2,2]+tbl1[1,2])*(tbl1[1,1]+tbl1[2,1])*(tbl1[1,1]+tbl1[1,2]))^(1/2))
MCC 

``` 
По корреляции Метьюса можно сделать вывод, что предсказанные классы хорошо совпадают с истиными.